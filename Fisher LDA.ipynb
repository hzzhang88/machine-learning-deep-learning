{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5258f62-cc54-49b0-b7e3-a9c246574ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys,itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331621f6-13c0-4b74-ad3b-2c1bc2a62549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    import csv\n",
    "    data = []\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file,delimiter= ',')\n",
    "        for row in csv_reader:\n",
    "            a = []\n",
    "            for i in range(len(row) -1):\n",
    "                a.append(float(row[i]))\n",
    "            a.append(int(row[len(row)-1]))\n",
    "            data.append(a)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a3aa89-02f6-419d-84d9-6cb591805e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fisher:\n",
    "    def __init__(self,data,num_dim):\n",
    "        self.data = data\n",
    "        self.num_dim = num_dim\n",
    "        self.columnlabel = len(self.data[0]) -1\n",
    "        self.dim = self.columnlabel\n",
    "        random.shuffle(self.data)\n",
    "        self.training_data = self.data[:int(len(self.data)*0.7)]\n",
    "        self.training_data = self.data[int(len(self.data)*0.7):]\n",
    "        self.group_data_by_classes()\n",
    "        self.calculate_means()\n",
    "        self.calculate_SB_SW()\n",
    "        self.calculate_eigen_values()\n",
    "        self.transform_data()\n",
    "        self.test_algorithm()\n",
    "        self.plot_normal_graph()\n",
    "        self.plot_transformed_data()\n",
    "        \n",
    "    def group_data_by_class(self):\n",
    "        self.grouped_data = {}\n",
    "        for i in self.training_data:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbc33ce-56f9-41e7-8145-ae562bff5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.sparse import eye\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.metrics import pairwise_kernels\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91bdac8b-6d53-4ea9-87ed-fa47cf4c28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kfda(BaseEstimator,ClassifierMixin,TransformerMixin):\n",
    "    \n",
    "    def __init__(self, n_components = 2, kernel = 'linear', robustness_offset = 1e-8, **kwds):\n",
    "        self.kernel = kernel\n",
    "        self.n_components = n_components\n",
    "        self.kwds = kwds\n",
    "        self.robustness_offset = robustness_offset\n",
    "        \n",
    "        if kernel is None:\n",
    "            self.kernel = 'linear'\n",
    "            \n",
    "    def fit(self,X,y):\n",
    "        X, y = check_X_y(X,y)\n",
    "        self.classes_ = unique_labels(y)\n",
    "        if self.n_components > self.classes_.size - 1:\n",
    "            warnings.warn(\n",
    "                \"n_components > classes_.size - 1.\"\n",
    "                \"Only the first classes_.size - 1 components will be valid.\"\n",
    "            )\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        y_onehot = OneHotEncoder().fit_transform(self.y_[:,np.newaxis])\n",
    "        K = pairwise_kernels(X,X,metric = self.kernel,**self.kwds)\n",
    "        # (k,n)X(n,n) --> (k,n) K_bar of each group\n",
    "        m_classes =   y_onehot.T @K/y_onehot.T.sum(1)\n",
    "        indices = (y_onehot@np.arange(self.classes_.size)).astype('i')\n",
    "        # m_classes[indices]  -- > H@K ----> generate the corresponding group mean (mi) for each observation(i)\n",
    "        # W = K(I-H)K\n",
    "        N = K@(K-m_classes[indices])\n",
    "        N += eye(self.y_.size)*self.robustness_offset\n",
    "        \n",
    "        # B = K(H-J)K\n",
    "        m_classes_centered = m_classes -K.mean(1)\n",
    "        M = m_classes_centered.T@m_classes_centered\n",
    "        \n",
    "        # HK = m_classes[indices]\n",
    "        # m_classes_centered = m_classes[indices] -K.mean(1)\n",
    "        # M = K@m_classes_centered\n",
    "        \n",
    "        # M @ x = w * N @ x.\n",
    "        # K(H-J)Ka = lamba*K(I-H)Ka\n",
    "        w, self.weights_ =eigsh(M,self.n_components,N,which = 'LM')\n",
    "        \n",
    "        #new point\n",
    "        # alpha.T@K\n",
    "        # for many points\n",
    "        # K(centers)@alpha: (k,n)X(n*1) = (k)\n",
    "        centroids_ = m_classes@self.weights_\n",
    "        self.clf_ = NearestCentroid().fit(centroids_, self.classes_)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self,X):\n",
    "        check_is_fitted(self)\n",
    "        # (1,n)@(n,1) --> a scaler\n",
    "        # (l,n)@(n,1) --> l\n",
    "        return pairwise_kernel(X,self.X_, metric = self.kernel, **self.kwds) @ self.weights_\n",
    "    \n",
    "    def predict(self,X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        \n",
    "        projected_points = self.transform(X) # return a scaler or a vector\n",
    "        predictions = self.clf_.predict(projected_points)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def fit_additional(self,X,y):\n",
    "        check_is_fitted(self)\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        new_classes = np.unique(y)\n",
    "        projections = self.transform(X)\n",
    "        y_onehot = OneHotEncoder().fit_transform(y[:,np.newaxis])\n",
    "        new_centroids = y_onehot.T @ projections / y_onehot.T.sum(1)\n",
    "        \n",
    "        concatenated_classes = np.concatenate([self.class_, new_classes])\n",
    "        concatenated_centroids = np.concatenate([self.clf_.centroids_, new_centroids])\n",
    "        self.clf_.fit(concatenated_centroids, concatenated_classes)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28098251-12cb-4ef4-abd2-ef79d6cdc86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 2., 2.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0,1,2,2,0,1,0])\n",
    "OneHotEncoder().fit_transform(y[:,np.newaxis]).toarray().T.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97f70be3-4546-45ea-b0b6-04f02cb5179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneHotEncoder().fit_transform(y[:,None]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9ab8a8c-20e7-4430-a998-4ee5753a255b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 2., 0., 1., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneHotEncoder().fit_transform(y[:,None])@ np.arange(unique_labels(y).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060cdb3-2501-4ca5-95af-7e0dffe03365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
