{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfbbc40b-9f1d-47a2-bb79-ce948f1640fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as pt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddac653-c890-40cd-872e-a5b4180249c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def loss_calc(y_true,y_pred):\n",
    "    loss = (1/len(y_true))*0.5*np.sum(np.square(y_true - y_pred))\n",
    "    return loss\n",
    "\n",
    "def gradient_calc(y_true,y_pred):\n",
    "    grad = -(y_true - y_pred)\n",
    "    return grad\n",
    "\n",
    "def tree_creator(r_state,X,y):\n",
    "    d_tree = DecisionTreeRegressor(random_state = r_state,criterion ='mse',\n",
    "                                  max_depth =2, min_samples_split =5,\n",
    "                                  min_samples_leaf = 5, max_features = 3)\n",
    "    d_tree.fit(X,y)\n",
    "    return d_tree\n",
    "\n",
    "def predict_grad_boost(models_tray,alpha,test_x, train_y):\n",
    "    initial_pred = np.array([np.mean(train_y)])\n",
    "    \n",
    "    final_pred = initial_pred.reshape(-1,1)\n",
    "    \n",
    "    for i in range(len(models_tray)):\n",
    "        model = models_tray[i]\n",
    "        temp_pred = (model.predict(test_x)).reshape(-1,1)\n",
    "        # final_pred -= alpha*temp_pred\n",
    "        final_pred += alpha*temp_pred\n",
    "    \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa64c943-c38b-41a1-bfcf-173d1a680227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_boost_train(train_x,train_y,alpha = 0.01, r_state = 100, n_iters = 101):\n",
    "    model_tray = []\n",
    "    loss_counter =[]\n",
    "    initial_pred = np.array([np.mean(train_y)])*len(train_y)\n",
    "    \n",
    "    model_pred = initial_pred.reshape(-1,1)\n",
    "    \n",
    "    for epoch in range(n_iters):\n",
    "        if epoch%100==0:\n",
    "            print('#---------- Epoch number :',epoch,' -----------#')\n",
    "        loss = loss_calc(y_true =  train_y,\n",
    "                        y_pred = model_pred)\n",
    "        loss_counter.append(loss)\n",
    "        \n",
    "        grads = gradient_calc(y_true = train_y,\n",
    "                             y_pred = model_pred)\n",
    "        \n",
    "        tree_grad = tree_creator(r_state = r_state,\n",
    "                                X= train_x,\n",
    "                                y = -grads) # y = grads\n",
    "        pred_m = (tree_grad.predict(train_x)).reshape(-1,1)\n",
    "        model_pred += alpha*pred_m # model_pred -= alpha*pred_m\n",
    "        model_tray.append(tree_grad)\n",
    "    \n",
    "    return model_tray,loss_counter, initial_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99350d12-e221-45cc-88d6-b82c1d84f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting(object):\n",
    "    \n",
    "    def __init__(self,n_estimators, learning_rate, min_samples_split,\n",
    "                min_impurity, max_depth,regression):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_impurity = min_impurity\n",
    "        self.max_depth = max_depth\n",
    "        self.regression = regression\n",
    "        \n",
    "        self.loss = mean_square_loss()\n",
    "        \n",
    "        if not self.regression:\n",
    "            self.loss = log_loss()\n",
    "            \n",
    "        self.trees = []\n",
    "        for _ in range(n_estimators):\n",
    "            tree = DecisionTreeRegressor(criterion ='mse',\n",
    "                                  max_depth =self.max_depth , min_samples_split =self.min_samples_split,\n",
    "                                  min_impurity_decrease= self.min_impurity, max_features = 3)\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "    def fit(self,X,y):\n",
    "        y_pred = np.full(np.shape(y),np.mean(y,axis = 0))\n",
    "        for i in range(self.n_estimators):\n",
    "            gradient = self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b175210f-aedd-4ba0-b065-b0f62e6de80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmultioutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform_average'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Mean squared error regression loss.\n",
       "\n",
       "Read more in the :ref:`User Guide <mean_squared_error>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
       "    Ground truth (correct) target values.\n",
       "\n",
       "y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
       "    Estimated target values.\n",
       "\n",
       "sample_weight : array-like of shape (n_samples,), default=None\n",
       "    Sample weights.\n",
       "\n",
       "multioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n",
       "    Defines aggregating of multiple output values.\n",
       "    Array-like value defines weights used to average errors.\n",
       "\n",
       "    'raw_values' :\n",
       "        Returns a full set of errors in case of multioutput input.\n",
       "\n",
       "    'uniform_average' :\n",
       "        Errors of all outputs are averaged with uniform weight.\n",
       "\n",
       "squared : bool, default=True\n",
       "    If True returns MSE value, if False returns RMSE value.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "loss : float or ndarray of floats\n",
       "    A non-negative floating point value (the best value is 0.0), or an\n",
       "    array of floating point values, one for each individual target.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.metrics import mean_squared_error\n",
       ">>> y_true = [3, -0.5, 2, 7]\n",
       ">>> y_pred = [2.5, 0.0, 2, 8]\n",
       ">>> mean_squared_error(y_true, y_pred)\n",
       "0.375\n",
       ">>> y_true = [3, -0.5, 2, 7]\n",
       ">>> y_pred = [2.5, 0.0, 2, 8]\n",
       ">>> mean_squared_error(y_true, y_pred, squared=False)\n",
       "0.612...\n",
       ">>> y_true = [[0.5, 1],[-1, 1],[7, -6]]\n",
       ">>> y_pred = [[0, 2],[-1, 2],[8, -5]]\n",
       ">>> mean_squared_error(y_true, y_pred)\n",
       "0.708...\n",
       ">>> mean_squared_error(y_true, y_pred, squared=False)\n",
       "0.822...\n",
       ">>> mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
       "array([0.41666667, 1.        ])\n",
       ">>> mean_squared_error(y_true, y_pred, multioutput=[0.3, 0.7])\n",
       "0.825...\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\conda\\lib\\site-packages\\sklearn\\metrics\\_regression.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2c149-d325-4aa0-895a-05c3d475534d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
